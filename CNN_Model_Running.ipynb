{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CNN_Model_Running.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjxrgFeOegOJ"
      },
      "source": [
        "# Cloud authentication.\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdKd6mybfH72"
      },
      "source": [
        "# Import, authenticate and initialize the Earth Engine library.\n",
        "import ee\n",
        "ee.Authenticate()\n",
        "ee.Initialize()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vrkg_ZQ4fKcc",
        "outputId": "f17e11bb-6cf0-4d6d-ebba-386edf3fdb56"
      },
      "source": [
        "# Tensorflow setup.\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oT60M7iKfL_0",
        "outputId": "dc735de0-c63e-46f5-c11c-304d0f8033e0"
      },
      "source": [
        "# Folium setup.\n",
        "import folium\n",
        "print(folium.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsSY1GjBfNZs"
      },
      "source": [
        "from functools import partial\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import backend as K"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcnXnjMp0-z3"
      },
      "source": [
        "from tensorflow.python.keras import metrics\n",
        "from tensorflow.python.keras import optimizers\n",
        "from tensorflow.python.keras import losses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JCfrCR4o_v9"
      },
      "source": [
        "# INSERT YOUR BUCKET HERE:\n",
        "BUCKET = 'tfworkshop'\n",
        "#BUCKET = 'practice_tanuja'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbNUfVmyycNE"
      },
      "source": [
        "from tensorflow.python.keras import backend\n",
        "\n",
        "def dice_coeff(y_true, y_pred, smooth=1):\n",
        "    y_true_f = backend.flatten(y_true)\n",
        "    y_pred_f = backend.flatten(y_pred)\n",
        "    intersection = backend.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (backend.sum(y_true_f) + backend.sum(y_pred_f) + smooth)\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    loss = 1 - dice_coeff(y_true, y_pred)\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhloQ3ipvVZv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "113b7803-20b3-40cd-f7e0-e5e39af0f258"
      },
      "source": [
        "# Specify names locations for outputs in Cloud Storage. \n",
        "FOLDER = 'HKH/Tanuja/New_data8'\n",
        "TRAINING_BASE = 'training'\n",
        "VALIDATION_BASE = 'validation'\n",
        "TESTING_BASE = 'testing'\n",
        "\n",
        "# Specify inputs (Landsat bands) to the model and the response variable.\n",
        "opticalBands = ['blue', 'green', 'red',\"vnir\",\"swir\",\"NDVI\"]\n",
        "BANDS = opticalBands\n",
        "RESPONSE = 'class'\n",
        "FEATURES = BANDS + [RESPONSE]\n",
        "\n",
        "# Specify the size and shape of patches expected by the model.\n",
        "KERNEL_SIZE = 128\n",
        "KERNEL_SHAPE = [KERNEL_SIZE, KERNEL_SIZE]\n",
        "\n",
        "\n",
        "COLUMNS = [\n",
        "  tf.io.FixedLenFeature(shape=KERNEL_SHAPE, dtype=tf.float32) for k in FEATURES\n",
        "]\n",
        "FEATURES_DICT = dict(zip(FEATURES, COLUMNS))\n",
        "print(FEATURES_DICT)\n",
        "\n",
        "#Sizes of the training and evaluation datasets.\n",
        "TRAIN_SIZE = 4000\n",
        "EVAL_SIZE = 2000\n",
        "\n",
        "# Specify model training parameters.\n",
        "BATCH_SIZE = 8\n",
        "#EPOCHS = 5\n",
        "BUFFER_SIZE = 2000\n",
        "#OPTIMIZER = 'SGD'\n",
        "OPTIMIZER = 'adam'\n",
        "LOSS = 'MeanSquaredError'\n",
        "METRICS = ['RootMeanSquaredError']\n",
        "\n",
        "\n",
        "# BUFFER_SIZE = 2000\n",
        "# #OPTIMIZER = 'Adam'\n",
        "# LOSS = dice_loss\n",
        "# METRICS = [\n",
        "#     metrics.get('RootMeanSquaredError'),\n",
        "#     metrics.get('MeanAbsoluteError'),\n",
        "#     metrics.get('Accuracy'),\n",
        "#     dice_coeff,\n",
        "# ]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'blue': FixedLenFeature(shape=[128, 128], dtype=tf.float32, default_value=None), 'green': FixedLenFeature(shape=[128, 128], dtype=tf.float32, default_value=None), 'red': FixedLenFeature(shape=[128, 128], dtype=tf.float32, default_value=None), 'vnir': FixedLenFeature(shape=[128, 128], dtype=tf.float32, default_value=None), 'NDVI': FixedLenFeature(shape=[128, 128], dtype=tf.float32, default_value=None), 'class': FixedLenFeature(shape=[128, 128], dtype=tf.float32, default_value=None)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUq73KIaiAWv"
      },
      "source": [
        "def normalized_difference(a, b):\n",
        "  \"\"\"Compute normalized difference of two inputs.\n",
        "\n",
        "  Compute (a - b) / (a + b).  If the denomenator is zero, add a small delta.\n",
        "\n",
        "  Args:\n",
        "    a: an input tensor with shape=[1]\n",
        "    b: an input tensor with shape=[1]\n",
        "\n",
        "  Returns:\n",
        "    The normalized difference as a tensor.\n",
        "  \"\"\"\n",
        "  nd = (a - b) / (a + b)\n",
        "  nd_inf = (a - b) / (a + b + 0.000001)\n",
        "  return tf.where(tf.math.is_finite(nd), nd, nd_inf)\n",
        "\n",
        "def add_NDVI(features):\n",
        "  \"\"\"Add NDVI to the dataset.\n",
        "  Args:\n",
        "    features: a dictionary of input tensors keyed by feature name.\n",
        "    label: the target label\n",
        "\n",
        "  Returns:\n",
        "    A tuple of the input dictionary with an NDVI tensor added and the label.\n",
        "  \"\"\"\n",
        "  print('hello')\n",
        "  features['NDVI'] = normalized_difference(features['vnir'], features['red'])\n",
        "  return features\n",
        "\n",
        "# def add_NDBI(features, label):\n",
        "#   \"\"\"Add NDVI to the dataset.\n",
        "#   Args:\n",
        "#     features: a dictionary of input tensors keyed by feature name.\n",
        "#     label: the target label\n",
        "\n",
        "#   Returns:\n",
        "#     A tuple of the input dictionary with an NDVI tensor added and the label.\n",
        "#   \"\"\"\n",
        "#   features['NDBI'] = normalized_difference(features['swir'], features['vnir'])\n",
        "#   return features, label\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kQ7RUoFL6Ac"
      },
      "source": [
        "# Data parsing and preparation \n",
        "def parse_tfrecord(example_proto):\n",
        "  \"\"\"The parsing function.\n",
        "  Read a serialized example into the structure defined by FEATURES_DICT.\n",
        "  Args:\n",
        "    example_proto: a serialized Example.\n",
        "  Returns:\n",
        "    A dictionary of tensors, keyed by feature name.\n",
        "  \"\"\"\n",
        "  return tf.io.parse_single_example(example_proto, FEATURES_DICT)\n",
        "\n",
        "# def parse_tfrecord(example_proto):\n",
        "#   \"\"\"The parsing function.\n",
        "#   Read a serialized example into the structure defined by FEATURES_DICT.\n",
        "#   Args:\n",
        "#     example_proto: a serialized Example.\n",
        "#   Returns:\n",
        "#     A dictionary of tensors, keyed by feature name.\n",
        "#   \"\"\"\n",
        "#   parsed_features = tf.io.parse_single_example(example_proto, FEATURES_DICT)\n",
        "#   labels = parsed_features.pop(RESPONSE)\n",
        "#   return parsed_features, tf.cast(labels, tf.int32)\n",
        "  \n",
        "def to_tuple(inputs):\n",
        "  \"\"\"Function to convert a dictionary of tensors to a tuple of (inputs, outputs).\n",
        "  Turn the tensors returned by parse_tfrecord into a stack in HWC shape.\n",
        "  Args:\n",
        "    inputs: A dictionary of tensors, keyed by feature name.\n",
        "  Returns:\n",
        "    A tuple of (inputs, outputs).\n",
        "  \"\"\"\n",
        "  inputsList = [inputs.get(key) for key in FEATURES]\n",
        "  stacked = tf.stack(inputsList, axis=0)\n",
        "  # Convert from CHW to HWC\n",
        "  stacked = tf.transpose(stacked, [1, 2, 0])\n",
        "  print(BANDS)\n",
        "  return stacked[:,:,:len(BANDS)], stacked[:,:,len(BANDS):]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osF6t7cZCxvd"
      },
      "source": [
        "def get_dataset(pattern,training=False):\n",
        "    \"\"\"Function to read, parse and format to tuple a set of input tfrecord files.\n",
        "    Get all the files matching the pattern, parse and convert to tuple.\n",
        "    Args:\n",
        "    pattern: A file pattern to match in a Cloud Storage bucket.\n",
        "    Returns: \n",
        "    A tf.data.Dataset\n",
        "    \"\"\"\n",
        "    glob = tf.io.gfile.glob(pattern)\n",
        "    dataset = tf.data.TFRecordDataset(glob, compression_type='GZIP')\n",
        "    dataset = dataset.map(parse_tfrecord, num_parallel_calls=5)\n",
        "    dataset = dataset.map(to_tuple, num_parallel_calls=5)\n",
        "    if training:\n",
        "        dataset = dataset.map(transform)\n",
        "    return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwCn5znSCoyW"
      },
      "source": [
        "# custom function to randomly augment the data during training\n",
        "def transform(features,labels):\n",
        "    x = tf.random.uniform(())\n",
        "    # flip image on horizontal axis\n",
        "    if x < 0.12: \n",
        "        feat = tf.image.flip_left_right(features)\n",
        "        labl = tf.image.flip_left_right(labels)\n",
        "    # flip image on vertical axis\n",
        "    elif tf.math.logical_and(x >=0.12, x < 0.24):\n",
        "        feat = tf.image.flip_up_down(features)\n",
        "        labl = tf.image.flip_up_down(labels)\n",
        "    # transpose image on bottom left corner\n",
        "    elif tf.math.logical_and(x >=0.24, x < 0.36):\n",
        "        feat = tf.image.flip_left_right(tf.image.flip_up_down(features))\n",
        "        labl = tf.image.flip_left_right(tf.image.flip_up_down(labels))\n",
        "    # rotate to the left 90 degrees\n",
        "    elif tf.math.logical_and(x >=0.36, x < 0.48):\n",
        "        feat = tf.image.rot90(features,k=1)\n",
        "        labl = tf.image.rot90(labels,k=1)\n",
        "    # rotate to the left 180 degrees\n",
        "    elif tf.math.logical_and(x >=0.48, x < 0.60):\n",
        "        feat = tf.image.rot90(features,k=2)\n",
        "        labl = tf.image.rot90(labels,k=2)\n",
        "    # rotate to the left 270 degrees\n",
        "    elif tf.math.logical_and(x >=0.60, x < 0.72):\n",
        "        feat = tf.image.rot90(features,k=3)\n",
        "        labl = tf.image.rot90(labels,k=3)\n",
        "    # transpose image on bottom right corner\n",
        "    elif tf.math.logical_and(x >=0.72, x < 0.84):\n",
        "        feat = tf.image.flip_left_right(tf.image.rot90(features,k=2))\n",
        "        labl = tf.image.flip_left_right(tf.image.rot90(labels,k=2))\n",
        "    else:\n",
        "        feat = features\n",
        "        labl = labels\n",
        "    \n",
        "    return feat,labl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmfcMpZx1Yoe"
      },
      "source": [
        "def get_training_dataset():\n",
        "    \"\"\"Get the preprocessed training dataset\n",
        "    Returns: \n",
        "    A tf.data.Dataset of training data.\n",
        "    \"\"\"\n",
        "    glob = 'gs://' + BUCKET + '/' + FOLDER + '/' + TRAINING_BASE + '/' + '*'\n",
        "    #dataset = get_dataset(glob,training=True)\n",
        "    dataset = get_dataset(glob,training=True)\n",
        "    dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
        "    return dataset\n",
        "training = get_training_dataset()\n",
        "\n",
        "type(training)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVLP_YD0MLUB"
      },
      "source": [
        "def get_training_dataset():\n",
        "\t\"\"\"Get the preprocessed training dataset\n",
        "  Returns: \n",
        "    A tf.data.Dataset of training data.\n",
        "  \"\"\"\n",
        "\tglob = 'gs://' + BUCKET + '/' + FOLDER + '/' + TRAINING_BASE + '/' + '*'\n",
        "\tdataset = get_dataset(glob)\n",
        "\tdataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
        "\treturn dataset\n",
        "\n",
        "training = get_training_dataset()\n",
        "type(training)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZTWdrHdMTXJ",
        "outputId": "f1804d7e-079c-40f4-a11b-7617e5288072"
      },
      "source": [
        "def get_validation_dataset():\n",
        "\t\"\"\"Get the preprocessed validaton dataset\n",
        "  Returns: \n",
        "    A tf.data.Dataset of validation data.\n",
        "  \"\"\"\n",
        "\tglob = 'gs://' + BUCKET + '/' + FOLDER + '/' + VALIDATION_BASE + '/' + '*'\n",
        "\tdataset = get_dataset(glob)\n",
        "\tdataset = dataset.batch(1).repeat()\n",
        "\treturn dataset\n",
        "\n",
        "validation = get_validation_dataset()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['blue', 'green', 'red', 'vnir', 'NDVI']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "So6AzwGaMaPi",
        "outputId": "bb105255-9789-4ccb-fa6a-ca86664958df"
      },
      "source": [
        "def get_testing_dataset():\n",
        "  glob = 'gs://' + BUCKET + '/' + FOLDER + '/' + TESTING_BASE + '/' + '*'\n",
        "  dataset = get_dataset(glob)\n",
        "  dataset = dataset.batch(1).repeat()\n",
        "  return dataset\n",
        "testing = get_testing_dataset()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['blue', 'green', 'red', 'vnir', 'NDVI']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8jGt0BWJc-y"
      },
      "source": [
        "from tensorflow.python.keras import layers\n",
        "from tensorflow.python.keras import losses\n",
        "from tensorflow.python.keras import models\n",
        "from tensorflow.python.keras import metrics\n",
        "from tensorflow.python.keras import optimizers\n",
        "\n",
        "def conv_block(input_tensor, num_filters):\n",
        "\tencoder = layers.Conv2D(num_filters, (3, 3), padding='same')(input_tensor)\n",
        "\tencoder = layers.BatchNormalization()(encoder)\n",
        "\tencoder = layers.Activation('relu')(encoder)\n",
        "\tencoder = layers.Conv2D(num_filters, (3, 3), padding='same')(encoder)\n",
        "\tencoder = layers.BatchNormalization()(encoder)\n",
        "\tencoder = layers.Activation('relu')(encoder)\n",
        "\treturn encoder\n",
        "\n",
        "def encoder_block(input_tensor, num_filters):\n",
        "\tencoder = conv_block(input_tensor, num_filters)\n",
        "\tencoder_pool = layers.MaxPooling2D((2, 2), strides=(2, 2))(encoder)\n",
        "\treturn encoder_pool, encoder\n",
        "\n",
        "def decoder_block(input_tensor, concat_tensor, num_filters):\n",
        "\tdecoder = layers.Conv2DTranspose(num_filters, (2, 2), strides=(2, 2), padding='same')(input_tensor)\n",
        "\tdecoder = layers.concatenate([concat_tensor, decoder], axis=-1)\n",
        "\tdecoder = layers.BatchNormalization()(decoder)\n",
        "\tdecoder = layers.Activation('relu')(decoder)\n",
        "\tdecoder = layers.Conv2D(num_filters, (3, 3), padding='same')(decoder)\n",
        "\tdecoder = layers.BatchNormalization()(decoder)\n",
        "\tdecoder = layers.Activation('relu')(decoder)\n",
        "\tdecoder = layers.Conv2D(num_filters, (3, 3), padding='same')(decoder)\n",
        "\tdecoder = layers.BatchNormalization()(decoder)\n",
        "\tdecoder = layers.Activation('relu')(decoder)\n",
        "\treturn decoder\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqY9vGrhqTh9"
      },
      "source": [
        "def get_model():\n",
        "\tinputs = layers.Input(shape=[None, None, len(BANDS)]) # 256\n",
        "  #layers.concatenate([concat_tensor, decoder], axis=-1)\n",
        "  #inputs = layers.Concatenate()([, x2])\n",
        "\tencoder0_pool, encoder0 = encoder_block(inputs, 32) # 128\n",
        "\tencoder1_pool, encoder1 = encoder_block(encoder0_pool, 64) # 64\n",
        "\tencoder2_pool, encoder2 = encoder_block(encoder1_pool, 128) # 32\n",
        "\tencoder3_pool, encoder3 = encoder_block(encoder2_pool, 256) # 16\n",
        "\tencoder4_pool, encoder4 = encoder_block(encoder3_pool, 512) # 8\n",
        "\tcenter = conv_block(encoder4_pool, 1024) # center\n",
        "\tdecoder4 = decoder_block(center, encoder4, 512) # 16\n",
        "\tdecoder3 = decoder_block(decoder4, encoder3, 256) # 32\n",
        "\tdecoder2 = decoder_block(decoder3, encoder2, 128) # 64\n",
        "\tdecoder1 = decoder_block(decoder2, encoder1, 64) # 128\n",
        "\tdecoder0 = decoder_block(decoder1, encoder0, 32) # 256\n",
        "\toutputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(decoder0)\n",
        "\n",
        "\tmodel = models.Model(inputs=[inputs], outputs=[outputs])\n",
        "\n",
        "\tmodel.compile(\n",
        "\t\toptimizer=optimizers.get(OPTIMIZER), \n",
        "\t\tloss=losses.get(LOSS),\n",
        "\t\tmetrics=[metrics.get(metric) for metric in METRICS])\n",
        "\n",
        "\treturn model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2uUqaS1FTrm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "306b14ef-5454-4833-dbe1-26fa773d3c8d"
      },
      "source": [
        "#mount to google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/mnt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/mnt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ICQsqYkFZhQ"
      },
      "source": [
        "%cd /content/mnt/My Drive\n",
        "%ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HRW-ngcFx8z"
      },
      "source": [
        "\n",
        "!mkdir -p 29_09_newdata8_rgbifndvi_datatran_40_epoch\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9Qvu6BBpQUg"
      },
      "source": [
        "m = get_model()\n",
        "m.summary()\n",
        "\n",
        "history = m.fit(\n",
        "    x=training, \n",
        "    epochs=40, \n",
        "    steps_per_epoch=int(TRAIN_SIZE / BATCH_SIZE), \n",
        "    validation_data=testing,\n",
        "    validation_steps=EVAL_SIZE)\n",
        "\n",
        "m.save('29_09_newdata8_rgbifndvi_datatran_40_epoch/my_model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMOvBw9UR1Xu"
      },
      "source": [
        "plt.rcParams[\"figure.figsize\"] = (40,10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JBZF2jVLMjr"
      },
      "source": [
        "#loading the saved model \n",
        "MODEL_DIR = '29_09_newdata8_rgbifndvi_datatran_40_epoch/my_model'\n",
        "\n",
        "m = tf.keras.models.load_model(MODEL_DIR)\n",
        "m.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tjlBrvk0M5e"
      },
      "source": [
        "#moving model to google cloud storage\n",
        "!gsutil cp -r /content/mnt/MyDrive//29_09_newdata8_rgbifndvi_datatran_40_epoch gs://tfworkshop/HKH/Tanuja/29_09_newdata8_rgbifndvi_datatran_40_epoch\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFVdYW5Z8uei",
        "outputId": "de21bfff-d924-43d5-98e0-7d46c79d693b"
      },
      "source": [
        "#prediction\n",
        "# Specify names locations for outputs in Cloud Storage. \n",
        "FOLDER = 'Tanuja_HKH'\n",
        "\n",
        "# Specify inputs (Landsat bands) to the model and the response variable.\n",
        "opticalBands = ['B2', 'B3', 'B4', 'B5', 'B6', 'B7']\n",
        "\n",
        "BANDS = opticalBands \n",
        "\n",
        "# Specify the size and shape of patches expected by the model.\n",
        "KERNEL_SIZE = 128\n",
        "KERNEL_SHAPE = [KERNEL_SIZE, KERNEL_SIZE]\n",
        "COLUMNS = [\n",
        "  tf.io.FixedLenFeature(shape=KERNEL_SHAPE, dtype=tf.float32) for k in FEATURES\n",
        "]\n",
        "FEATURES_DICT = dict(zip(FEATURES, COLUMNS))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "128"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KScqw7Wk8FYL",
        "outputId": "c5b34a84-b633-40c8-f48f-5db8724dd696"
      },
      "source": [
        "# Use Sentinnel2 surface reflectance data for predictors.\n",
        "l8sr = ee.ImageCollection('COPERNICUS/S2_SR')\n",
        "BANDS = ['B2','B3','B4','B8','B11']\n",
        "\n",
        "#cloud masking function of sentinnel data\n",
        "def maskS2clouds(image):\n",
        "  qa = image.select('QA60')\n",
        "\n",
        "  # Bits 10 and 11 are clouds and cirrus, respectively.\n",
        "  cloudBitMask = 1 << 10;\n",
        "  cirrusBitMask = 1 << 11;\n",
        "\n",
        "  # Both flags should be set to zero, indicating clear conditions.\n",
        "  mask = qa.bitwiseAnd(cloudBitMask).eq(0)\n",
        "  mask = (qa.bitwiseAnd(cirrusBitMask).eq(0))\n",
        "  return image.updateMask(mask).divide(10000)\n",
        "\n",
        "image = l8sr.filterDate('2019-01-01', '2019-1-30').filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE',20)).map(maskS2clouds).median()\n",
        "image = image.unmask(0)\n",
        "\n",
        "nir = image.select('B8');\n",
        "red = image.select('B4');\n",
        "        \n",
        "ndvi = nir.subtract(red).divide(nir.add(red)).rename('NDVI');\n",
        "image = image.addBands(ndvi);\n",
        "\n",
        "image = image.select(['B2','B3','B4','B8','B11','NDVI'])\n",
        "image.bandNames().getInfo()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['B2', 'B3', 'B4', 'B8', 'B11', 'NDVI']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0A-hTAE7zhPd"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUJdZMYo9vPD"
      },
      "source": [
        "#image export function\n",
        "def doExport(out_image_base, kernel_buffer, region):\n",
        "  \"\"\"Run the image export task.  Block until complete.\n",
        "  \"\"\"\n",
        "  task = ee.batch.Export.image.toCloudStorage(\n",
        "    #image = image.select(BANDS),\n",
        "    image = image,\n",
        "    #image = image,\n",
        "    description = out_image_base,\n",
        "    bucket = BUCKET,\n",
        "    fileNamePrefix = FOLDER + '/' + out_image_base,\n",
        "    region = region.getInfo()['coordinates'],\n",
        "    scale = 10,\n",
        "    fileFormat = 'TFRecord',\n",
        "    maxPixels = 1e10,\n",
        "    formatOptions = {\n",
        "      'patchDimensions': KERNEL_SHAPE,\n",
        "      'kernelSize': kernel_buffer,\n",
        "      'compressed': True,\n",
        "      'maxFileSize': 104857600\n",
        "    }\n",
        "  )\n",
        "  task.start()\n",
        "\n",
        "  # Block until the task completes.\n",
        "  print('Running image export to Cloud Storage...')\n",
        "  import time\n",
        "  while task.active():\n",
        "    time.sleep(30)\n",
        "\n",
        "  # Error condition\n",
        "  if task.status()['state'] != 'COMPLETED':\n",
        "    print('Error with image export.')\n",
        "  else:\n",
        "    print('Image export completed.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4jxpZrjurzc"
      },
      "source": [
        "BANDS = ['B2','B3','B4','B8','B11','NDVI']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SDHFRBy93tB"
      },
      "source": [
        "def doPrediction(out_image_base, user_folder, kernel_buffer, region):\n",
        "  \"\"\"Perform inference on exported imagery, upload to Earth Engine.\n",
        "  \"\"\"\n",
        "\n",
        "  print('Looking for TFRecord files...')\n",
        "\n",
        "  # Get a list of all the files in the output bucket.\n",
        "  filesList = !gsutil ls 'gs://'{BUCKET}'/'{FOLDER}\n",
        "\n",
        "  # Get only the files generated by the image export.\n",
        "  exportFilesList = [s for s in filesList if out_image_base in s]\n",
        "\n",
        "  # Get the list of image files and the JSON mixer file.\n",
        "  imageFilesList = []\n",
        "  jsonFile = None\n",
        "  for f in exportFilesList:\n",
        "    if f.endswith('.tfrecord.gz'):\n",
        "      imageFilesList.append(f)\n",
        "    elif f.endswith('.json'):\n",
        "      jsonFile = f\n",
        "\n",
        "  # Make sure the files are in the right order.\n",
        "  imageFilesList.sort()\n",
        "\n",
        "  from pprint import pprint\n",
        "  pprint(imageFilesList)\n",
        "  print(jsonFile)\n",
        "\n",
        "  import json\n",
        "  # Load the contents of the mixer file to a JSON object.\n",
        "  jsonText = !gsutil cat {jsonFile}\n",
        "  # Get a single string w/ newlines from the IPython.utils.text.SList\n",
        "  mixer = json.loads(jsonText.nlstr)\n",
        "  pprint(mixer)\n",
        "  patches = mixer['totalPatches']\n",
        "\n",
        "  # Get set up for prediction.\n",
        "  x_buffer = int(kernel_buffer[0] / 2)\n",
        "  y_buffer = int(kernel_buffer[1] / 2)\n",
        "\n",
        "  buffered_shape = [\n",
        "      KERNEL_SHAPE[0] + kernel_buffer[0],\n",
        "      KERNEL_SHAPE[1] + kernel_buffer[1]]\n",
        "\n",
        "  imageColumns = [\n",
        "    tf.io.FixedLenFeature(shape=buffered_shape, dtype=tf.float32) \n",
        "      for k in BANDS\n",
        "  ]\n",
        "\n",
        "  imageFeaturesDict = dict(zip(BANDS, imageColumns))\n",
        "\n",
        "  def parse_image(example_proto):\n",
        "    return tf.io.parse_single_example(example_proto, imageFeaturesDict)\n",
        "\n",
        "  def toTupleImage(inputs):\n",
        "    inputsList = [inputs.get(key) for key in BANDS]\n",
        "    stacked = tf.stack(inputsList, axis=0)\n",
        "    stacked = tf.transpose(stacked, [1, 2, 0])\n",
        "    return stacked\n",
        "\n",
        "   # Create a dataset from the TFRecord file(s) in Cloud Storage.\n",
        "  imageDataset = tf.data.TFRecordDataset(imageFilesList, compression_type='GZIP')\n",
        "  imageDataset = imageDataset.map(parse_image, num_parallel_calls=5)\n",
        "  imageDataset = imageDataset.map(toTupleImage).batch(1)\n",
        "\n",
        "  # Perform inference.\n",
        "  print('Running predictions...')\n",
        "  predictions = m.predict(imageDataset, steps=patches, verbose=1)\n",
        "  # print(predictions[0])\n",
        "\n",
        "  print('Writing predictions...')\n",
        "  out_image_file = 'gs://' + BUCKET + '/' + FOLDER + '/' + out_image_base + '.TFRecord'\n",
        "  writer = tf.io.TFRecordWriter(out_image_file)\n",
        "  patches = 0\n",
        "  for predictionPatch in predictions:\n",
        "    print('Writing patch ' + str(patches) + '...')\n",
        "    predictionPatch = predictionPatch[\n",
        "        x_buffer:x_buffer+KERNEL_SIZE, y_buffer:y_buffer+KERNEL_SIZE]\n",
        "\n",
        "    # Create an example.\n",
        "    example = tf.train.Example(\n",
        "      features=tf.train.Features(\n",
        "        feature={\n",
        "          'impervious': tf.train.Feature(\n",
        "              float_list=tf.train.FloatList(\n",
        "                  value=predictionPatch.flatten()))\n",
        "        }\n",
        "      )\n",
        "    )\n",
        "    # Write the example.\n",
        "    writer.write(example.SerializeToString())\n",
        "    patches += 1\n",
        "\n",
        "  writer.close()\n",
        "\n",
        "  # Start the upload.\n",
        "  out_image_asset = user_folder + '/' + out_image_base\n",
        "  !earthengine upload image --asset_id={out_image_asset} {out_image_file} {jsonFile}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xd7gSV2s960J"
      },
      "source": [
        "# Output assets folder: YOUR FOLDER\n",
        "user_folder = 'users/tanujashrestha' # INSERT YOUR FOLDER HERE.\n",
        "FOLDER = 'HKH/Tanuja'\n",
        "# Base file name to use for TFRecord files and assets.\n",
        "\n",
        "bj_image_base = 'Kathmandu'\n",
        "\n",
        "#Note the above file is inside the 'urban256v3' folder\n",
        "\n",
        "# Half this will extend on the sides of each patch.\n",
        "bj_kernel_buffer = [128, 128]\n",
        "\n",
        "\n",
        "bj_region = ee.Geometry.Polygon( #for Kathmandu\n",
        "        [[[85.19264036381233,27.585543326088402],\n",
        "          [85.49476438724983,27.585543326088402],\n",
        "          [85.19264036381233,27.806237838670395],\n",
        "          [85.19264036381233,27.585543326088402]]], None, False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cV81OKnS-FX4",
        "outputId": "b41862fa-06a9-4fee-d018-18a97441d734"
      },
      "source": [
        "# Run the export.\n",
        "doExport(bj_image_base, bj_kernel_buffer, bj_region)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running image export to Cloud Storage...\n",
            "Image export completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCAOyMmv-IO-"
      },
      "source": [
        "# Run the prediction.\n",
        "doPrediction(bj_image_base, user_folder, bj_kernel_buffer,bj_region)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}